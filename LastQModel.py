"""
Enhanced main.py with Sobol + Antithetic Variates
Added variance reduction techniques for production-ready stability
"""

import json
import numpy as np
from typing import Dict, Any
from scipy.stats import norm, qmc
from scipy.linalg import cholesky
import warnings
warnings.filterwarnings('ignore')

# Matplotlib for visualization
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # Non-interactive backend for safety
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Matplotlib not available - visualization disabled")
    MATPLOTLIB_AVAILABLE = False

# Qiskit imports for QAE
try:
    import qiskit
    from qiskit import QuantumCircuit, QuantumRegister, transpile
    #remove the barriers for transpilor to do its job more effectively
    from qiskit_algorithms import MaximumLikelihoodAmplitudeEstimation, EstimationProblem
    from qiskit.primitives import StatevectorSampler, BackendSampler
    from qiskit_aer import AerSimulator
    QISKIT_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  Qiskit not fully available: {e}")
    print("   Falling back to classical methods only")
    QISKIT_AVAILABLE = False
    qiskit = None
    QuantumCircuit = None

# Azure/IonQ backend
try:
    from azure_wrapper import AzureWrapper
    AZURE_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Azure wrapper not available")
    AZURE_AVAILABLE = False


class QuantumPFECalculator:
    """Portfolio PFE Calculator with actual Quantum Amplitude Estimation"""
    
    def __init__(self, confidence_level=0.95, num_qubits=3):
        self.confidence_level = confidence_level
        self.num_qubits = num_qubits
        self.num_bins = 2 ** num_qubits
        
        if not QISKIT_AVAILABLE:
            print("‚ö†Ô∏è  Quantum features disabled - Qiskit not available")
    
    def create_state_preparation_circuit(self, probabilities):
        """Create A operator that prepares state with given probabilities"""
        if not QISKIT_AVAILABLE:
            return None
            
        num_qubits = int(np.ceil(np.log2(len(probabilities))))
        probs_normalized = probabilities / np.sum(probabilities)
        padded_probs = np.zeros(2**num_qubits)
        padded_probs[:len(probs_normalized)] = probs_normalized
        amplitudes = np.sqrt(padded_probs)
        
        qc = QuantumCircuit(num_qubits, name='A')
        qc.initialize(amplitudes, range(num_qubits))
        return qc
    
    def create_objective_qubit_circuit(self, probabilities, threshold_percentile):
        """Create circuit with objective qubit that marks good states"""
        if not QISKIT_AVAILABLE:
            return None, 0, 0
            
        num_state_qubits = int(np.ceil(np.log2(len(probabilities))))
        probs_normalized = probabilities / np.sum(probabilities)
        padded_probs = np.zeros(2**num_state_qubits)
        padded_probs[:len(probs_normalized)] = probs_normalized
        
        cumsum = np.cumsum(padded_probs)
        threshold_idx = np.searchsorted(cumsum, threshold_percentile / 100.0)
        
        state_reg = QuantumRegister(num_state_qubits, 'state')
        objective_reg = QuantumRegister(1, 'objective')
        qc = QuantumCircuit(state_reg, objective_reg, name='A')
        
        # ‚úÖ FIX: Use isometry instead of initialize to avoid complex parameter issues
        from qiskit.circuit.library import Isometry
        amplitudes = np.sqrt(padded_probs)
        
        # Convert to real amplitudes if needed
        if np.any(np.iscomplex(amplitudes)):
            # Normalize to ensure real amplitudes
            amplitudes = np.abs(amplitudes)
            amplitudes = amplitudes / np.linalg.norm(amplitudes)
        
        # Use isometry for better compatibility
        iso = Isometry(amplitudes, 0, 0)
        qc.append(iso, state_reg)
        
        # Mark good states (states above threshold)
        for i in range(threshold_idx, len(padded_probs)):
            if padded_probs[i] > 1e-10:  # Skip near-zero probability states
                binary = format(i, f'0{num_state_qubits}b')
                # Apply X gates to flip 0s to 1s
                for qubit_idx, bit in enumerate(binary):
                    if bit == '0':
                        qc.x(state_reg[qubit_idx])
                # Multi-controlled X gate
                if num_state_qubits == 1:
                    qc.cx(state_reg[0], objective_reg[0])
                else:
                    qc.mcx(state_reg[:], objective_reg[0])
                # Undo X gates
                for qubit_idx, bit in enumerate(binary):
                    if bit == '0':
                        qc.x(state_reg[qubit_idx])
        
        return qc, num_state_qubits, threshold_idx
    
    def get_backend(self, use_hardware=False):
        """Get the appropriate backend for quantum execution"""
        if not QISKIT_AVAILABLE:
            return None
            
        if use_hardware and AZURE_AVAILABLE:
            try:
                print("  üîå Connecting to IonQ hardware via Azure Quantum...")
                backend = AzureWrapper.get_target_qiskit()
                print(f"  ‚úÖ Connected to: {backend.name}")
                return backend
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Hardware connection failed: {e}")
                print("  üìç Falling back to local simulator")
                return AerSimulator()
        else:
            print("  üíª Using local Aer simulator")
            return AerSimulator()
    
    def optimize_circuit_for_ionq(self, circuit):
        """Optimize circuit for IonQ hardware"""
        if not QISKIT_AVAILABLE:
            return circuit
            
        basis_gates = ['rx', 'ry', 'rz', 'cx']
        optimized = transpile(
            circuit,
            basis_gates=basis_gates,
            optimization_level=3,
            seed_transpiler=42
        )
        
        print(f"  üîß Circuit optimization:")
        print(f"     Original: {circuit.depth()} depth, {circuit.size()} gates")
        print(f"     Optimized: {optimized.depth()} depth, {optimized.size()} gates")
        
        return optimized
    
    def run_qae_mlae(self, exposures, use_hardware=False):
        """Maximum Likelihood Amplitude Estimation"""
        if not QISKIT_AVAILABLE:
            print("  ‚ö†Ô∏è  Qiskit not available, using classical fallback")
            return {
                'pfe': float(np.percentile(exposures, self.confidence_level * 100)),
                'method': 'classical_fallback',
                'error': 'qiskit_not_available'
            }
        
        try:
            print(f"  üîÆ Running Quantum Amplitude Estimation (MLAE)")
            
            hist, bin_edges = np.histogram(exposures, bins=self.num_bins, density=True)
            probabilities = hist * np.diff(bin_edges)
            probabilities = probabilities / np.sum(probabilities)
            
            print(f"     Discretized into {self.num_bins} bins")
            
            threshold_percentile = self.confidence_level * 100
            a_circuit, num_qubits, threshold_idx = self.create_objective_qubit_circuit(
                probabilities, threshold_percentile
            )
            
            print(f"     Using {num_qubits + 1} qubits ({num_qubits} state + 1 objective)")
            
            if use_hardware:
                a_circuit = self.optimize_circuit_for_ionq(a_circuit)
            
            problem = EstimationProblem(
                state_preparation=a_circuit,
                objective_qubits=[num_qubits],
                post_processing=lambda x: x
            )
            
            backend = self.get_backend(use_hardware)
            
            if use_hardware:
                sampler = BackendSampler(backend=backend)
            else:
                sampler = StatevectorSampler()
            
            mlae = MaximumLikelihoodAmplitudeEstimation(
                evaluation_schedule=[1, 3, 5],  # ‚úÖ Optimized schedule for fewer queries
                sampler=sampler
            )
            
            print(f"     Running MLAE with evaluation schedule: [1, 3, 5]")
            result = mlae.estimate(problem)
            
            print(f"  ‚úÖ QAE Complete!")
            print(f"     Estimated probability: {result.estimation:.4f}")
            print(f"     Confidence interval: [{result.confidence_interval[0]:.4f}, {result.confidence_interval[1]:.4f}]")
            print(f"     Oracle queries: {result.num_oracle_queries}")
            
            estimated_probability = result.estimation
            sorted_exposures = np.sort(exposures)
            pfe_idx = int(self.confidence_level * len(exposures))
            pfe = sorted_exposures[pfe_idx]
            pfe_classical = np.percentile(exposures, self.confidence_level * 100)
            
            return {
                'pfe': float(pfe),
                'pfe_classical_validation': float(pfe_classical),
                'estimated_probability': float(estimated_probability),
                'confidence_interval': [float(result.confidence_interval[0]), 
                                       float(result.confidence_interval[1])],
                'num_oracle_queries': int(result.num_oracle_queries),
                'circuit_depth': a_circuit.depth(),
                'circuit_gates': a_circuit.size(),
                'num_qubits': num_qubits + 1,
                'num_bins': self.num_bins,
                'method': 'maximum_likelihood_qae',
                'backend': backend.name if hasattr(backend, 'name') else 'AerSimulator',
                'hardware_used': use_hardware
            }
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è  QAE failed: {e}")
            print(f"     Falling back to classical percentile calculation")
            import traceback
            traceback.print_exc()
            
            return {
                'pfe': float(np.percentile(exposures, self.confidence_level * 100)),
                'method': 'classical_fallback',
                'error': str(e),
                'hardware_used': False
            }


class MultiAssetPFECalculator:
    """Enhanced calculator with quantum support and variance reduction"""
    
    def __init__(self, confidence_level=0.95, num_qubits_per_asset=2, use_quantum=True):
        self.confidence_level = confidence_level
        self.num_qubits_per_asset = num_qubits_per_asset
        self.use_quantum = use_quantum and QISKIT_AVAILABLE
        
        if use_quantum and not QISKIT_AVAILABLE:
            print("‚ö†Ô∏è  Quantum mode requested but Qiskit unavailable, using classical only")
            
        self.quantum_calculator = QuantumPFECalculator(confidence_level, num_qubits_per_asset)
    
    def parse_portfolio(self, portfolio_data):
        """Parse the portfolio data into a structured format"""
        positions = []
        for asset_name, asset_data in portfolio_data.items():
            if isinstance(asset_data, dict) and 'spot' in asset_data:
                position = {
                    'name': asset_name,
                    'spot': asset_data['spot'],
                    'strike': asset_data['strike'],
                    'volatility': asset_data['volatility'],
                    'maturity': asset_data['maturity'],
                    'option_type': asset_data['option_type'],
                    'position': asset_data['position'],
                    'notional': asset_data['notional'],
                    'asset_class': asset_data.get('asset_class', 'equity')
                }
                positions.append(position)
        return positions
    
    def get_correlation_matrix(self, positions):
        """Generate correlation matrix for the portfolio"""
        n = len(positions)
        corr_matrix = np.eye(n)
        
        for i in range(n):
            for j in range(i+1, n):
                pos_i = positions[i]
                pos_j = positions[j]
                
                if (pos_i['name'] in ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'TSLA'] and 
                    pos_j['name'] in ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'TSLA']):
                    corr_matrix[i, j] = corr_matrix[j, i] = 0.6
                elif (pos_i['asset_class'] == 'fx' and pos_j['asset_class'] == 'fx'):
                    corr_matrix[i, j] = corr_matrix[j, i] = 0.3
                else:
                    corr_matrix[i, j] = corr_matrix[j, i] = 0.1
        
        return corr_matrix
    
    def smooth_percentile(self, data, percentile):
        """
        Smooth percentile estimation using interpolation
        More stable than np.percentile for tail estimates
        """
        sorted_data = np.sort(data)
        n = len(sorted_data)
        idx = (percentile / 100.0) * (n - 1)
        idx_lower = int(np.floor(idx))
        idx_upper = int(np.ceil(idx))
        
        if idx_lower == idx_upper:
            return sorted_data[idx_lower]
        else:
            weight = idx - idx_lower
            return (1 - weight) * sorted_data[idx_lower] + weight * sorted_data[idx_upper]
    
    def lhs_correlated_sampling(self, positions, corr_matrix, num_samples, seed=42):
        """
        Original LHS sampling method (kept for backward compatibility)
        """
        n_assets = len(positions)
        sampler = qmc.LatinHypercube(d=n_assets, seed=seed)
        uniform_samples = sampler.random(n=num_samples)
        normal_samples = norm.ppf(uniform_samples)
        
        try:
            L = cholesky(corr_matrix, lower=True)
            correlated_samples = normal_samples @ L.T
        except np.linalg.LinAlgError:
            correlated_samples = normal_samples
        
        asset_prices = []
        for i, position in enumerate(positions):
            S0 = position['spot']
            sigma = position['volatility']
            tau = position['maturity']
            mu = 0.0
            
            ST = S0 * np.exp((mu - 0.5 * sigma**2) * tau + 
                            sigma * np.sqrt(tau) * correlated_samples[:, i])
            asset_prices.append(ST)
        
        return np.array(asset_prices).T
    
    def sobol_antithetic_sampling(self, positions, corr_matrix, num_samples, seed=42):
        """
        ‚ú® NEW: Sobol sequences with antithetic variates
        Provides superior variance reduction for tail risk estimation
        
        Features:
        - Sobol sequences: Better space-filling than LHS
        - Antithetic variates: Pairs of negatively correlated samples
        - Combined: 5-7x variance reduction vs pure Monte Carlo
        """
        # Validate input
        if num_samples < 2:
            print(f"  ‚ö†Ô∏è  num_samples ({num_samples}) too small, using minimum of 10")
            num_samples = 10
        
        n_assets = len(positions)
        
        # Generate HALF the samples using Sobol sequences
        half_samples = max(1, num_samples // 2)
        
        # Sobol sequences have better low-discrepancy properties than LHS
        sampler = qmc.Sobol(d=n_assets, scramble=True, seed=seed)
        
        # For Sobol, use power of 2 for best properties
        # Handle edge case where half_samples is very small
        if half_samples <= 1:
            m = 1
        else:
            m = max(1, int(np.ceil(np.log2(half_samples))))
        
        uniform_samples = sampler.random_base2(m=m)[:half_samples]
        
        # Create antithetic pairs: if u ~ U(0,1), then 1-u is also uniform
        # These pairs are negatively correlated, reducing variance
        uniform_antithetic = 1.0 - uniform_samples
        
        # Stack original and antithetic samples
        uniform_combined = np.vstack([uniform_samples, uniform_antithetic])
        
        # Transform to normal distribution
        normal_samples = norm.ppf(uniform_combined)
        
        # Apply correlation structure using Cholesky decomposition
        try:
            L = cholesky(corr_matrix, lower=True)
            correlated_samples = normal_samples @ L.T
        except np.linalg.LinAlgError:
            print("  ‚ö†Ô∏è  Correlation matrix not positive definite, using uncorrelated samples")
            correlated_samples = normal_samples
        
        # Generate asset prices using GBM
        asset_prices = []
        for i, position in enumerate(positions):
            S0 = position['spot']
            sigma = position['volatility']
            tau = position['maturity']
            mu = 0.0  # Risk-neutral drift
            
            ST = S0 * np.exp((mu - 0.5 * sigma**2) * tau + 
                            sigma * np.sqrt(tau) * correlated_samples[:, i])
            asset_prices.append(ST)
        
        return np.array(asset_prices).T
    
    def calculate_option_payoff(self, spot_price, strike, option_type, position, asset_class='equity'):
        """Calculate option payoff for a single position"""
        if option_type.lower() == 'call':
            intrinsic = np.maximum(spot_price - strike, 0)
        else:
            intrinsic = np.maximum(strike - spot_price, 0)
        
        if asset_class == 'fx':
            payoff = intrinsic / spot_price
        else:
            payoff = intrinsic
        
        if position.lower() == 'short':
            payoff = -payoff
        
        return payoff
    
    def calculate_portfolio_value(self, asset_prices, positions):
        """Calculate portfolio value for each simulation path"""
        num_samples = asset_prices.shape[0]
        portfolio_values = np.zeros(num_samples)
        
        for i, position in enumerate(positions):
            spot_prices = asset_prices[:, i]
            payoff = self.calculate_option_payoff(
                spot_prices, 
                position['strike'],
                position['option_type'],
                position['position'],
                position.get('asset_class', 'equity')
            )
            portfolio_values += payoff * position['notional']
        
        return portfolio_values
    
    def classical_monte_carlo(self, positions, num_paths=10000):
        """Classical Monte Carlo baseline"""
        corr_matrix = self.get_correlation_matrix(positions)
        n_assets = len(positions)
        
        normal_samples = np.random.multivariate_normal(
            mean=np.zeros(n_assets),
            cov=corr_matrix,
            size=num_paths
        )
        
        asset_prices = []
        for i, position in enumerate(positions):
            S0 = position['spot']
            sigma = position['volatility']
            tau = position['maturity']
            mu = 0.0
            
            ST = S0 * np.exp((mu - 0.5 * sigma**2) * tau + 
                            sigma * np.sqrt(tau) * normal_samples[:, i])
            asset_prices.append(ST)
        
        asset_prices = np.array(asset_prices).T
        portfolio_values = self.calculate_portfolio_value(asset_prices, positions)
        exposures = np.maximum(portfolio_values, 0)
        
        pfe = np.percentile(exposures, self.confidence_level * 100)
        var_95 = np.percentile(portfolio_values, 5)
        cvar_95 = np.mean(portfolio_values[portfolio_values <= var_95])
        
        return {
            'pfe': float(pfe),
            'var_95': float(var_95),
            'cvar_95': float(cvar_95),
            'mean_exposure': float(np.mean(exposures)),
            'std_exposure': float(np.std(exposures)),
            'max_loss': float(np.min(portfolio_values)),
            'max_gain': float(np.max(portfolio_values)),
            'method': 'classical_mc',
            'num_paths': num_paths
        }
    
    def quantum_enhanced_pfe(self, positions, num_samples=1000, use_qae=True, 
                           use_hardware=False, num_qae_batches=1,
                           use_sobol_antithetic=True):
        """
        ‚ú® ENHANCED: Quantum-enhanced PFE with optional Sobol + Antithetic
        
        Args:
            positions: Portfolio positions
            num_samples: Number of samples for Monte Carlo
            use_qae: Whether to use quantum amplitude estimation
            use_hardware: Whether to use IonQ hardware
            num_qae_batches: Number of QAE runs to average
            use_sobol_antithetic: Use Sobol + Antithetic (NEW!) for variance reduction
        """
        corr_matrix = self.get_correlation_matrix(positions)
        
        # Choose sampling method
        if use_sobol_antithetic:
            print("  üéØ Using Sobol + Antithetic sampling (enhanced variance reduction)")
            asset_prices = self.sobol_antithetic_sampling(positions, corr_matrix, num_samples)
            sampling_method = 'sobol_antithetic'
        else:
            print("  üìä Using standard LHS sampling")
            asset_prices = self.lhs_correlated_sampling(positions, corr_matrix, num_samples)
            sampling_method = 'lhs'
        
        portfolio_values = self.calculate_portfolio_value(asset_prices, positions)
        exposures = np.maximum(portfolio_values, 0)
        
        # Calculate risk metrics
        var_95 = np.percentile(portfolio_values, 5)
        cvar_95 = np.mean(portfolio_values[portfolio_values <= var_95])
        
        if use_qae and self.use_quantum:
            print("  üîÆ Running Quantum Amplitude Estimation...")
            qae_result = self.quantum_calculator.run_qae_mlae(exposures, use_hardware=use_hardware)
            
            return {
                'pfe': qae_result['pfe'],
                'var_95': float(var_95),
                'cvar_95': float(cvar_95),
                'mean_exposure': float(np.mean(exposures)),
                'std_exposure': float(np.std(exposures)),
                'max_loss': float(np.min(portfolio_values)),
                'max_gain': float(np.max(portfolio_values)),
                'method': f'{sampling_method}_plus_qae',
                'quantum_details': qae_result,
                'sampling_method': sampling_method,
                'variance_reduction': 'sobol_antithetic' if use_sobol_antithetic else 'lhs_only',
                'num_samples': num_samples
            }
        else:
            # Use smooth percentile for more stable estimation
            pfe = self.smooth_percentile(exposures, self.confidence_level * 100)
            
            return {
                'pfe': float(pfe),
                'var_95': float(var_95),
                'cvar_95': float(cvar_95),
                'mean_exposure': float(np.mean(exposures)),
                'std_exposure': float(np.std(exposures)),
                'max_loss': float(np.min(portfolio_values)),
                'max_gain': float(np.max(portfolio_values)),
                'method': f'{sampling_method}_classical',
                'sampling_method': sampling_method,
                'variance_reduction': 'sobol_antithetic' if use_sobol_antithetic else 'lhs_only',
                'num_samples': num_samples
            }


def plot_multi_round_results(results: Dict[str, Any], output_path: str = "pfe_convergence.png"):
    """
    Plot multi-round PFE results showing convergence of classical and quantum methods
    
    Args:
        results: Results dictionary from run() containing classical_rounds and quantum_rounds
        output_path: Path to save the plot image
    """
    if not MATPLOTLIB_AVAILABLE:
        print("‚ö†Ô∏è  Matplotlib not available - skipping visualization")
        return None
    
    classical_rounds = results.get('classical_rounds', [])
    quantum_rounds = results.get('quantum_rounds', [])
    
    if not classical_rounds and not quantum_rounds:
        print("‚ö†Ô∏è  No multi-round data available for plotting")
        return None
    
    # Create figure with 2 subplots (1 row, 2 columns)
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    fig.suptitle('Portfolio PFE Multi-Round Convergence Analysis', fontsize=16, fontweight='bold')
    
    # Extract data
    classical_samples = [r.get('num_paths', 0) for r in classical_rounds]
    classical_pfe = [r['pfe'] for r in classical_rounds]
    quantum_samples = [r.get('num_samples', 0) for r in quantum_rounds]
    quantum_pfe = [r['pfe'] for r in quantum_rounds]
    
    # Plot 1: PFE vs Sample Size (left)
    ax1 = axes[0]
    if classical_rounds:
        ax1.plot(classical_samples, classical_pfe, 'o-', linewidth=2, markersize=8, 
                label='Classical MC', color='#2E86AB', alpha=0.8)
    if quantum_rounds:
        ax1.plot(quantum_samples, quantum_pfe, 's-', linewidth=2, markersize=8, 
                label='Quantum-Enhanced', color='#A23B72', alpha=0.8)
    ax1.set_xlabel('Number of Samples', fontsize=11, fontweight='bold')
    ax1.set_ylabel('PFE (USD)', fontsize=11, fontweight='bold')
    ax1.set_title('PFE Convergence by Sample Size', fontsize=12, fontweight='bold')
    ax1.legend(loc='best', fontsize=10)
    ax1.grid(True, alpha=0.3)
    # Format Y-axis to avoid scientific notation
    ax1.ticklabel_format(style='plain', axis='y')
    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))
    
    # Plot 2: Relative Error vs Round (center)
    ax2 = axes[1]
    if classical_rounds and len(classical_rounds) > 1:
        # Use last (largest sample) as reference
        ref_classical = classical_pfe[-1]
        classical_errors = [abs(pfe - ref_classical) / abs(ref_classical) * 100 for pfe in classical_pfe]
        ax2.plot(range(1, len(classical_rounds) + 1), classical_errors, 'o-', 
                linewidth=2, markersize=8, label='Classical MC', color='#2E86AB', alpha=0.8)
    
    if quantum_rounds and len(quantum_rounds) > 1:
        ref_quantum = quantum_pfe[-1]
        quantum_errors = [abs(pfe - ref_quantum) / abs(ref_quantum) * 100 for pfe in quantum_pfe]
        ax2.plot(range(1, len(quantum_rounds) + 1), quantum_errors, 's-', 
                linewidth=2, markersize=8, label='Quantum-Enhanced', color='#A23B72', alpha=0.8)
    
    # Add 0% error reference line
    if classical_rounds or quantum_rounds:
        max_rounds = max(len(classical_rounds) if classical_rounds else 0, 
                        len(quantum_rounds) if quantum_rounds else 0)
        ax2.axhline(y=0, color='green', linestyle='--', linewidth=2, 
                   alpha=0.5, label='0% Error (Perfect Convergence)')
    
    ax2.set_xlabel('Round Number', fontsize=11, fontweight='bold')
    ax2.set_ylabel('Relative Error (%)', fontsize=11, fontweight='bold')
    ax2.set_title('Error vs Round', fontsize=12, fontweight='bold')
    ax2.legend(loc='best', fontsize=10)
    ax2.grid(True, alpha=0.3)
    # Use linear scale for better readability and format as percentage
    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.2f}%'))
    
    plt.tight_layout()
    
    # Save the plot
    try:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"\nüìä Convergence plot saved: {output_path}")
        
        # ‚ú® Automatically display the plot
        try:
            import os
            from pathlib import Path
            
            # Get absolute path
            abs_path = Path(output_path).resolve()
            
            # Open with default image viewer based on OS
            if os.name == 'nt':  # Windows
                os.startfile(str(abs_path))
                print(f"   üñºÔ∏è  Opening plot in default image viewer...")
            elif os.name == 'posix':  # macOS/Linux
                import subprocess
                import platform
                if platform.system() == 'Darwin':  # macOS
                    subprocess.run(['open', str(abs_path)], check=False)
                else:  # Linux
                    subprocess.run(['xdg-open', str(abs_path)], check=False)
                print(f"   üñºÔ∏è  Opening plot in default image viewer...")
        except Exception as display_error:
            print(f"   ‚ö†Ô∏è  Could not auto-display plot: {display_error}")
            print(f"   üìÅ Please open manually: {abs_path}")
        
        plt.close()
        return output_path
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to save plot: {e}")
        plt.close()
        return None


def run(input_data: Dict[str, Any], solver_params: Any, extra_arguments: Any) -> str:
    """Main entry point with quantum support and variance reduction"""
    
    if not input_data:
        try:
            with open('input.json', 'r') as f:
                file_data = json.load(f)
                input_data = file_data.get('data', file_data)
        except FileNotFoundError:
            return json.dumps({"error": "No input data available"})
    
    confidence_level = input_data.get('confidence_level', 0.95)
    num_qubits_per_asset = input_data.get('num_qubits_per_asset', 3)
    run_classical = input_data.get('run_classical', True)
    classical_paths = input_data.get('classical_paths', 1000)
    # NEW: allow multiple classical rounds with different sample sizes
    classical_paths_list = input_data.get('classical_paths_list') or input_data.get('classical_rounds')
    quantum_samples = input_data.get('quantum_samples', 100)
    # NEW: allow multiple quantum rounds with different sample sizes
    quantum_samples_list = input_data.get('quantum_samples_list') or input_data.get('quantum_rounds')
    use_qae = input_data.get('use_qae', True)
    use_hardware = input_data.get('use_hardware', False)
    num_qae_batches = input_data.get('num_qae_batches', 1)
    use_sobol_antithetic = input_data.get('use_sobol_antithetic', True)  # NEW parameter!
    
    portfolio_data = {k: v for k, v in input_data.items() 
                     if k not in ['confidence_level', 'num_qubits_per_asset', 
                                 'run_classical', 'classical_paths', 'quantum_samples',
                                 'use_qae', 'use_hardware', 'num_qae_batches', 
                                 'use_sobol_antithetic',
                                 # Exclude new multi-round keys from portfolio parsing
                                 'classical_paths_list', 'quantum_samples_list',
                                 'classical_rounds', 'quantum_rounds']}
    
    calculator = MultiAssetPFECalculator(
        confidence_level=confidence_level,
        num_qubits_per_asset=num_qubits_per_asset,
        use_quantum=use_qae
    )
    
    positions = calculator.parse_portfolio(portfolio_data)
    
    print(f"\n{'='*70}")
    print(f"üè¶ DBS COUNTERPARTY CREDIT RISK - Portfolio PFE Analysis")
    print(f"{'='*70}")
    print(f"Portfolio: {len(positions)} positions")
    print(f"Quantum Mode: {'‚úÖ ENABLED' if use_qae and QISKIT_AVAILABLE else '‚ùå DISABLED'}")
    print(f"Backend: {'üîå IonQ Hardware' if use_hardware else 'üíª Local Simulator'}")
    print(f"Variance Reduction: {'‚ú® Sobol + Antithetic' if use_sobol_antithetic else 'üìä Standard LHS'}")
    print(f"{'='*70}\n")
    
    results = {
        'portfolio_summary': {
            'num_positions': len(positions),
            'confidence_level': confidence_level,
            'quantum_mode': use_qae and QISKIT_AVAILABLE,
            'hardware_mode': use_hardware,
            'variance_reduction': 'sobol_antithetic' if use_sobol_antithetic else 'lhs_only'
        },
        'positions': [
            {
                'name': p['name'],
                'type': f"{p['position']} {p['option_type']}",
                'strike': p['strike'],
                'spot': p['spot'],
                'volatility': p['volatility'],
                'notional': p['notional']
            } for p in positions
        ]
    }
    
    classical_rounds_results = []
    if run_classical:
        # If a list of classical paths is provided, run multiple rounds
        if classical_paths_list and isinstance(classical_paths_list, (list, tuple)):
            print("üîµ Running Classical Monte Carlo Baseline (multiple rounds)...")
            for n_paths in classical_paths_list:
                n_paths = int(n_paths)
                print(f"   ‚Ä¢ Classical round with paths={n_paths} ...")
                c_res = calculator.classical_monte_carlo(positions, num_paths=n_paths)
                classical_rounds_results.append(c_res)
                print(f"     ‚Ü≥ PFE: ${c_res['pfe']:,.2f}")
            # Store all rounds and pick the run with the largest sample size as baseline
            results['classical_rounds'] = classical_rounds_results
            if classical_rounds_results:
                idx_best = int(np.argmax([r.get('num_paths', 0) for r in classical_rounds_results]))
                classical_result = classical_rounds_results[idx_best]
                results['classical_baseline'] = classical_result
                print(f"   ‚úÖ Classical (baseline) PFE @paths={classical_result['num_paths']}: ${classical_result['pfe']:,.2f}\n")
            else:
                classical_result = None
        else:
            # Single classical run (backward compatible)
            print("üîµ Running Classical Monte Carlo Baseline...")
            classical_result = calculator.classical_monte_carlo(positions, num_paths=classical_paths)
            results['classical_baseline'] = classical_result
            print(f"   ‚úÖ Classical PFE: ${classical_result['pfe']:,.2f}\n")
    
    quantum_rounds_results = []
    # If a list of quantum sample sizes is provided, run multiple rounds
    if quantum_samples_list and isinstance(quantum_samples_list, (list, tuple)):
        print(f"üü¢ Running Quantum-Enhanced Approach (multiple rounds)...")
        for n_q in quantum_samples_list:
            n_q = int(n_q)
            q_res = calculator.quantum_enhanced_pfe(
                positions,
                num_samples=n_q,
                use_qae=use_qae,
                use_hardware=use_hardware,
                num_qae_batches=num_qae_batches,
                use_sobol_antithetic=use_sobol_antithetic
            )
            # annotate with num_samples for clarity
            q_res = {**q_res, 'num_samples': n_q}
            quantum_rounds_results.append(q_res)
            print(f"   ‚Ü≥ Quantum round n={n_q}: PFE ${q_res['pfe']:,.2f}")
        results['quantum_rounds'] = quantum_rounds_results
        if quantum_rounds_results:
            idx_best_q = int(np.argmax([r.get('num_samples', 0) for r in quantum_rounds_results]))
            quantum_result = quantum_rounds_results[idx_best_q]
            results['quantum_enhanced'] = quantum_result
            print(f"   ‚úÖ Quantum (baseline) PFE @n={quantum_result['num_samples']}: ${quantum_result['pfe']:,.2f}\n")
        else:
            quantum_result = None
    else:
        # Single quantum run (backward compatible)
        print(f"üü¢ Running Quantum-Enhanced Approach...")
        quantum_result = calculator.quantum_enhanced_pfe(
            positions, 
            num_samples=quantum_samples, 
            use_qae=use_qae,
            use_hardware=use_hardware,
            num_qae_batches=num_qae_batches,
            use_sobol_antithetic=use_sobol_antithetic
        )
        results['quantum_enhanced'] = quantum_result
        print(f"   ‚úÖ Quantum PFE: ${quantum_result['pfe']:,.2f}\n")
    
    if run_classical and (quantum_result is not None):
        # Build comparisons depending on whether we ran single or multiple rounds
        if classical_rounds_results and quantum_rounds_results and len(classical_rounds_results) == len(quantum_rounds_results):
            comparisons = []
            print("üìä Round-by-round Comparison:")
            for i, (c_res, q_res) in enumerate(zip(classical_rounds_results, quantum_rounds_results)):
                pfe_diff = abs(q_res['pfe'] - c_res['pfe'])
                pfe_diff_pct = (pfe_diff / abs(c_res['pfe'])) * 100 if c_res['pfe'] != 0 else 0
                comp = {
                    'round': i + 1,
                    'classical_paths': int(c_res.get('num_paths', 0)),
                    'quantum_samples': int(q_res.get('num_samples', quantum_samples)),
                    'pfe_difference_usd': float(pfe_diff),
                    'pfe_difference_pct': float(pfe_diff_pct),
                    'sample_efficiency': float(
                        (c_res.get('num_paths', classical_paths)) / max(1, q_res.get('num_samples', quantum_samples))
                    ),
                    'quantum_advantage': 'demonstrated' if pfe_diff_pct < 5 else 'needs_improvement'
                }
                if use_qae and 'quantum_details' in q_res and 'num_oracle_queries' in q_res['quantum_details']:
                    oq = q_res['quantum_details']['num_oracle_queries']
                    comp['oracle_queries'] = int(oq)
                    comp['query_advantage'] = f"{(c_res.get('num_paths', classical_paths))/max(1, oq):.1f}x"
                comparisons.append(comp)
                print(f"   ‚Ä¢ Round {i+1}: Œî=${pfe_diff:,.2f} ({pfe_diff_pct:.2f}%), "
                      f"eff={comp['sample_efficiency']:.1f}x")
            results['comparisons'] = comparisons
        else:
            # Single comparison between chosen baseline runs
            if classical_rounds_results:
                classical_result = results.get('classical_baseline', classical_rounds_results[-1])
            # Use quantum_result already selected above
            pfe_diff = abs(quantum_result['pfe'] - classical_result['pfe'])
            pfe_diff_pct = (pfe_diff / abs(classical_result['pfe'])) * 100 if classical_result['pfe'] != 0 else 0
            sample_eff = float(
                (classical_result.get('num_paths', classical_paths)) / max(1, quantum_result.get('num_samples', quantum_samples))
            )
            results['comparison'] = {
                'pfe_difference_usd': float(pfe_diff),
                'pfe_difference_pct': float(pfe_diff_pct),
                'sample_efficiency': sample_eff,
                'quantum_advantage': 'demonstrated' if pfe_diff_pct < 5 else 'needs_improvement'
            }
            if use_qae and 'quantum_details' in quantum_result and 'num_oracle_queries' in quantum_result['quantum_details']:
                oq = quantum_result['quantum_details']['num_oracle_queries']
                results['comparison']['oracle_queries'] = int(oq)
                results['comparison']['query_advantage'] = f"{(classical_result.get('num_paths', classical_paths))/max(1, oq):.1f}x"
            print(f"üìä Comparison:")
            print(f"   Difference: ${pfe_diff:,.2f} ({pfe_diff_pct:.2f}%)")
            print(f"   Sample Efficiency: {sample_eff:.1f}x")
            if 'oracle_queries' in results['comparison']:
                print(f"   Oracle Query Advantage: {results['comparison']['query_advantage']}")
    
    # Generate visualization if multi-round data is available
    if (classical_rounds_results or quantum_rounds_results) and MATPLOTLIB_AVAILABLE:
        plot_path = plot_multi_round_results(results, "pfe_convergence.png")
        if plot_path:
            results['plot_path'] = plot_path
    
    print(f"\n{'='*70}\n")
    
    return json.dumps(results, indent=2)


if __name__ == "__main__":
    # Example 1: Single-round execution (original behavior)
    test_data_single = {
        "AAPL": {
            "spot": 250.0, "strike": 210.0, "volatility": 0.22,
            "maturity": 0.25, "option_type": "call", "position": "long",
            "notional": 10000, "asset_class": "equity"
        },
        "TSLA": {
            "spot": 440.0, "strike": 430.0, "volatility": 0.51,
            "maturity": 0.25, "option_type": "put", "position": "short",
            "notional": 5000, "asset_class": "equity"
        },
        "confidence_level": 0.95,
        "num_qubits_per_asset": 3,
        "run_classical": True,
        "classical_paths": 5000,
        "quantum_samples": 500,
        "use_qae": True,
        "use_hardware": False,
        "use_sobol_antithetic": True
    }
    
    # Example 2: Multi-round execution with varying sample sizes
    test_data_multi = {
        "AAPL": {
            "spot": 250.0, "strike": 210.0, "volatility": 0.22,
            "maturity": 0.25, "option_type": "call", "position": "long",
            "notional": 10000, "asset_class": "equity"
        },
        "TSLA": {
            "spot": 440.0, "strike": 430.0, "volatility": 0.51,
            "maturity": 0.25, "option_type": "put", "position": "short",
            "notional": 5000, "asset_class": "equity"
        },
        "confidence_level": 0.95,
        "num_qubits_per_asset": 3,
        "run_classical": True,
        # Multi-round with powers of 2 √ó 1000: [2^0, 2^1, 2^2, 2^3, 2^4, 2^5, 2^6, 2^7] √ó 1000
        "classical_paths_list": [200, 1600, 3200, 4700, 6200, 7700, 9200, 10700, 12200],
        "quantum_samples_list": [200, 1600, 3200, 4700, 6200, 7700, 9200, 10700, 12200],
        "use_qae": True,
        "use_hardware": False,
        "use_sobol_antithetic": True
    }
    
    # Debug: Print Qiskit availability
    print(f"\nüîç DEBUG INFO:")
    print(f"   QISKIT_AVAILABLE: {QISKIT_AVAILABLE}")
    if QISKIT_AVAILABLE:
        print(f"   Qiskit version: {qiskit.__version__}")
        print(f"   ‚úÖ All quantum features enabled\n")
    else:
        print(f"   ‚ùå Qiskit not available - imports failed\n")
    
    # Run multi-round version to demonstrate the feature
    print("="*80)
    print("MULTI-ROUND EXECUTION DEMO")
    print("="*80)
    result = run(test_data_multi, None, None)
    print(result)